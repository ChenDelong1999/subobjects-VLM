{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from visual_tokenizer import get_visual_tokenizer\n",
    "from utils.visualization import visualize_masks\n",
    "from data import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = get_dataset('imagenet', '/share/datasets/imagenet', split='train')\n",
    "# dataset = get_dataset('coco', '/share/datasets/coco2017', split='train')\n",
    "dataset = get_dataset('clevr_caption', '/home/dchenbs/workspace/datasets/CLEVR_v1.0', split='train')\n",
    "# dataset = get_dataset('image_paragraph_captioning', '/home/dchenbs/workspace/datasets/VisualGenome', split='train')\n",
    "\n",
    "# datset = get_dataset('sharegpt4v', '/home/dchenbs/workspace/datasets/sharegpt4v/ShareGPT4V/sharegpt4v_mix665k_cap23k_coco-ap9k_lcs3k_sam9k_div2k.json', split='train')\n",
    "# dataset = get_dataset('sharegpt4v', '/home/dchenbs/workspace/datasets/sharegpt4v/ShareGPT4V/share-captioner_coco_lcs_sam_1246k_1107.json', split='train')\n",
    "# dataset = get_dataset('sharegpt4v', '/home/dchenbs/workspace/datasets/sharegpt4v/ShareGPT4V/sharegpt4v_instruct_gpt4-vision_cap100k.json', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resolution = 768\n",
    "\n",
    "token_per_side = 6\n",
    "max_tokens = token_per_side * token_per_side\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/patch_8_per_side_random.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/patch_8_per_side_raster.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/directsam_0424.json'))\n",
    "config = json.load(open('configs/visual_tokenizer/directsam_tiny.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(config)\n",
    "config['threshold'] = 0.1\n",
    "\n",
    "visual_tokenizer = get_visual_tokenizer(**config, image_resolution=image_resolution, max_tokens=max_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    # sample = dataset[i]\n",
    "    sample = dataset[random.randint(0, len(dataset) - 1)]\n",
    "    image = sample['image'].resize((image_resolution,image_resolution))\n",
    "    batch_masks = visual_tokenizer(image).cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(visualize_masks(image, batch_masks[0]))\n",
    "    plt.title((np.sum(batch_masks[0], axis=(1, 2)) > 0).sum())\n",
    "\n",
    "\n",
    "    labels = np.zeros_like(batch_masks[0][0]).astype(np.int32)\n",
    "    for i, mask in enumerate(batch_masks[0]):\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        labels += (i + 1) * mask\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(labels, cmap='plasma')\n",
    "    plt.title('order')\n",
    "\n",
    "    print(sample['text'])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    for i in range(token_per_side * token_per_side):\n",
    "        plt.subplot(token_per_side, token_per_side, i + 1)\n",
    "        plt.imshow(batch_masks[0][i])\n",
    "        plt.axis('off')\n",
    "        plt.title(batch_masks[0][i].sum())\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics and Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10\n",
    "effective_masks = []\n",
    "mask_sizes = []\n",
    "for _ in tqdm.tqdm(range(steps)):\n",
    "    image = dataset[random.randint(0, len(dataset) - 1)]['image']\n",
    "    image = image.resize((image_resolution, image_resolution))\n",
    "    masks = visual_tokenizer(image)[0].cpu().numpy()\n",
    "\n",
    "    effective_masks.append((np.sum(masks, axis=(1, 2))>0).sum())\n",
    "    mask_sizes.append(np.sum(masks, axis=(1, 2)))\n",
    "\n",
    "mask_sizes = np.array(mask_sizes) / (image_resolution * image_resolution)* 100\n",
    "avg_mask_sizes = np.mean(mask_sizes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for sample_mask_sizes in mask_sizes:\n",
    "    plt.plot(sample_mask_sizes, alpha=0.1)\n",
    "\n",
    "plt.plot(avg_mask_sizes, color='black', linewidth=2)\n",
    "\n",
    "# plot horizontal line of 10%, 1%, 0.1% and mark text\n",
    "for y in [1, 50, 10, 1, 0.1]:\n",
    "    plt.axhline(y=y, color='r', linestyle='--')\n",
    "    plt.text(0, y*1.1, f'{y}%', color='r')\n",
    "\n",
    "# # plot vertical line of 32 tokens, 64 tokens, 128 tokens and mark text\n",
    "for x in [4, 8, 32]:\n",
    "    plt.axvline(x=x-1, color='b', linestyle='--')\n",
    "    plt.scatter(x-1, avg_mask_sizes[x-1], color='b')\n",
    "    plt.text(x+1, avg_mask_sizes[x-1], f'{x} tokens ({avg_mask_sizes[x-1]:.3f}%)', color='b')\n",
    "\n",
    "#log y axis\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(effective_masks, bins=50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "univlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
