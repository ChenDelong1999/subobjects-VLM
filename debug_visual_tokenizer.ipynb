{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from visual_tokenizer import get_visual_tokenizer\n",
    "from utils.visualization import visualize_masks\n",
    "from HEIT.metrics import create_circular_kernel, masks_to_contour, contour_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/delong/miniconda3/envs/subobjects/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'contour'],\n",
      "    num_rows: 1314\n",
      "})\n",
      "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7FECC4494CA0>, 'contour': <PIL.PngImagePlugin.PngImageFile image mode=1 size=1024x1024 at 0x7FECC4494E50>}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "splits = [\n",
    "    'SA1B', 'COCONut_relabeld_COCO_val', 'EntitySeg', 'PascalPanopticParts', 'plantorgans', 'MapillaryMetropolis', \n",
    "    'cityscapes', 'NYUDepthv2', 'tcd', 'FoodSeg103', 'ADE20k', 'WireFrame', 'ISAID', 'PhenoBench', 'EgoHOS', 'LIP', \n",
    "    'SOBA', 'CIHP', 'LoveDA', 'SPIN', 'SUIM', 'MyFood', 'DIS5K_DIS_VD', 'DUTS_TE', 'Fashionpedia', 'PartImageNetPP', \n",
    "    'SeginW', 'LVIS', 'PACO', 'DRAM'\n",
    "    ]\n",
    "dataset = load_dataset(\"chendelong/HEIT\", split='EntitySeg')\n",
    "print(dataset)\n",
    "print(dataset[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'configs/visual_tokenizer/directsam/directsam_tiny_dsa_100ep@0.1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m image_resolution \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m384\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# config = json.load(open('configs/visual_tokenizer/patch/patch_8_per_side_raster.json'))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# config = json.load(open('configs/visual_tokenizer/patch_16_per_side_random.json'))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfigs/visual_tokenizer/directsam/directsam_tiny_dsa_100ep@0.1.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# config = json.load(open('configs/visual_tokenizer/directsam/directsam_tiny_dsa_100ep@0.1_x2.json'))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# config = json.load(open('configs/visual_tokenizer/superpixel/superpixel_slic.json'))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# config['threshold'] = 0.1\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# config['crop'] = 3\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(config)\n",
      "File \u001b[0;32m~/miniconda3/envs/subobjects/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'configs/visual_tokenizer/directsam/directsam_tiny_dsa_100ep@0.1.json'"
     ]
    }
   ],
   "source": [
    "image_resolution = 384\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/patch/patch_8_per_side_raster.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/patch_16_per_side_random.json'))\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/directsam/directsam_tiny_dsa_100ep@0.1.json'))\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/directsam/directsam_tiny_dsa_100ep@0.1_x2.json'))\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/superpixel/superpixel_slic.json'))\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/panoptic/panoptic_mask2former_small.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/panoptic/panoptic_oneformer_large.json'))\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/sam/sam_vit_l.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/sam/sam_vit_h_64points_1layer.json'))\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/sam/fastsam.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/sam/mobilesamv2.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/sam/efficientvit.json'))\n",
    "\n",
    "# config['threshold'] = 0.1\n",
    "# config['crop'] = 3\n",
    "print(config)\n",
    "\n",
    "# config['threshold'] = 0.1\n",
    "max_tokens = 256\n",
    "\n",
    "visual_tokenizer = get_visual_tokenizer(**config, image_resolution=image_resolution, max_tokens=max_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Global circular kernel\n",
    "tolerance = 10\n",
    "CIRCULAR_KERNEL = create_circular_kernel(tolerance)\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    sample = dataset[i]\n",
    "    sample = dataset[random.randint(0, len(dataset) - 1)]\n",
    "    image = sample['image'].resize((image_resolution,image_resolution))\n",
    "    batch_masks = visual_tokenizer(image).cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(visualize_masks(image, batch_masks[0]))\n",
    "    plt.title(f\"{(np.sum(batch_masks[0], axis=(1, 2)) > 0).sum()} tokens\")\n",
    "\n",
    "    labels = np.zeros_like(batch_masks[0][0]).astype(np.int32)\n",
    "    for i, mask in enumerate(batch_masks[0]):\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        labels += (i + 1) * mask\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(labels, cmap='plasma')\n",
    "    plt.title('order')\n",
    "    plt.show()\n",
    "\n",
    "    gt_contour = np.array(sample['contour'])\n",
    "    gt_contour[:tolerance] = gt_contour[-tolerance:] = gt_contour[:, :tolerance] = gt_contour[:, -tolerance:] = 0\n",
    "    pred_contour = masks_to_contour(batch_masks[0], CIRCULAR_KERNEL)\n",
    "\n",
    "    # calculate recall\n",
    "    recall = contour_recall(gt_contour, pred_contour)\n",
    "    missing_contour = np.logical_and(gt_contour, np.logical_not(pred_contour))\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(gt_contour, cmap='Greens')\n",
    "    plt.title('Ground Truth')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(missing_contour, cmap='Reds')\n",
    "    plt.imshow(image.resize((1024, 1024)), alpha=0.1)\n",
    "    plt.title(f'Recall: {recall:.2f}')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(missing_contour, cmap='Reds')\n",
    "    plt.imshow(pred_contour, cmap='Blues', alpha=0.3)\n",
    "    plt.title('Predicted')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "\n",
    "    # token_per_side = root of max_tokens + 1\n",
    "    token_per_side = min(6, int(np.sqrt(max_tokens)))\n",
    "\n",
    "    for i in range(token_per_side * token_per_side):\n",
    "        plt.subplot(token_per_side, token_per_side, i + 1)\n",
    "        plt.imshow(batch_masks[0][i], cmap='Blues')\n",
    "        plt.imshow(image, alpha=0.1)\n",
    "        plt.axis('off')\n",
    "        # plt.title(batch_masks[0][i].sum())\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics and Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5\n",
    "effective_masks = []\n",
    "mask_sizes = []\n",
    "for _ in tqdm.tqdm(range(steps)):\n",
    "    image = dataset[random.randint(0, len(dataset) - 1)]['image']\n",
    "    image = image.resize((image_resolution, image_resolution))\n",
    "    masks = visual_tokenizer(image)[0].cpu().numpy()\n",
    "\n",
    "    effective_masks.append((np.sum(masks, axis=(1, 2))>0).sum())\n",
    "    mask_sizes.append(np.sum(masks, axis=(1, 2)))\n",
    "\n",
    "mask_sizes = np.array(mask_sizes) / (image_resolution * image_resolution)* 100\n",
    "avg_mask_sizes = np.mean(mask_sizes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "\n",
    "# for sample_mask_sizes in mask_sizes:\n",
    "#     plt.plot(sample_mask_sizes, alpha=0.1)\n",
    "\n",
    "# plt.plot(avg_mask_sizes, color='black', linewidth=2)\n",
    "\n",
    "# # plot horizontal line of 10%, 1%, 0.1% and mark text\n",
    "# for y in [1, 50, 10, 1, 0.1]:\n",
    "#     plt.axhline(y=y, color='r', linestyle='--')\n",
    "#     plt.text(0, y*1.1, f'{y}%', color='r')\n",
    "\n",
    "# # # plot vertical line of 32 tokens, 64 tokens, 128 tokens and mark text\n",
    "# for x in [4, 9, 16, 25, 36, 64, 81, 100]:\n",
    "#     if x >= max_tokens:\n",
    "#         continue\n",
    "#     plt.axvline(x=x-1, color='b', linestyle='--')\n",
    "#     plt.scatter(x-1, avg_mask_sizes[x-1], color='b')\n",
    "#     plt.text(x+1, avg_mask_sizes[x-1], f'{x} tokens ({avg_mask_sizes[x-1]:.3f}%)', color='b')\n",
    "\n",
    "# #log y axis\n",
    "# plt.xlim(0, max_tokens)\n",
    "# plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.hist(effective_masks, bins=50)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subobjects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
