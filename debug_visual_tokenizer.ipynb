{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from visual_tokenizer import get_visual_tokenizer\n",
    "from utils.visualization import visualize_masks\n",
    "from HEIT.token_vs_contour_recall import create_circular_kernel, masks_to_contour, contour_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "splits = [\n",
    "    'SA1B', 'COCONut_relabeld_COCO_val', 'EntitySeg', 'PascalPanopticParts', 'plantorgans', 'MapillaryMetropolis', \n",
    "    'cityscapes', 'NYUDepthv2', 'tcd', 'FoodSeg103', 'ADE20k', 'WireFrame', 'ISAID', 'PhenoBench', 'EgoHOS', 'LIP', \n",
    "    'SOBA', 'CIHP', 'LoveDA', 'SPIN', 'SUIM', 'MyFood', 'DIS5K_DIS_VD', 'DUTS_TE', 'Fashionpedia', 'PartImageNetPP', \n",
    "    'SeginW', 'LVIS', 'PACO', 'DRAM'\n",
    "    ]\n",
    "dataset = load_dataset(\"chendelong/HEIT\", split='COCONut_relabeld_COCO_val')\n",
    "print(dataset)\n",
    "print(dataset[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resolution = 1024\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/patch/patch_8_per_side_raster.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/patch_16_per_side_random.json'))\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/directsam/directsam_tiny_dsa_50ep.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/directsam/directsam_b0.json'))\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/superpixel.json'))\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/panoptic/panoptic_mask2former_small.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/panoptic/panoptic_oneformer_large.json'))\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/sam/sam_vit_l.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/sam/sam_vit_h_64points_1layer.json'))\n",
    "\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/sam/fastsam.json'))\n",
    "config = json.load(open('configs/visual_tokenizer/sam/mobilesamv2.json'))\n",
    "\n",
    "print(config)\n",
    "\n",
    "visual_tokenizer = get_visual_tokenizer(**config, image_resolution=image_resolution, max_tokens=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Global circular kernel\n",
    "tolerance = 10\n",
    "CIRCULAR_KERNEL = create_circular_kernel(tolerance)\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    sample = dataset[i]\n",
    "    # sample = dataset[random.randint(0, len(dataset) - 1)]\n",
    "    image = sample['image'].resize((image_resolution,image_resolution))\n",
    "    batch_masks = visual_tokenizer(image).cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(visualize_masks(image, batch_masks[0]))\n",
    "    plt.title(f\"{(np.sum(batch_masks[0], axis=(1, 2)) > 0).sum()} tokens\")\n",
    "\n",
    "    labels = np.zeros_like(batch_masks[0][0]).astype(np.int32)\n",
    "    for i, mask in enumerate(batch_masks[0]):\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        labels += (i + 1) * mask\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(labels, cmap='plasma_r')\n",
    "    plt.title('order')\n",
    "    plt.show()\n",
    "\n",
    "    gt_contour = np.array(sample['contour'])\n",
    "    gt_contour[:tolerance] = gt_contour[-tolerance:] = gt_contour[:, :tolerance] = gt_contour[:, -tolerance:] = 0\n",
    "    pred_contour = masks_to_contour(batch_masks[0], CIRCULAR_KERNEL)\n",
    "\n",
    "    # calculate recall\n",
    "    recall = contour_recall(gt_contour, pred_contour)\n",
    "    missing_contour = np.logical_and(gt_contour, np.logical_not(pred_contour))\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(gt_contour, cmap='Greens')\n",
    "    plt.title('Ground Truth')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(missing_contour, cmap='Reds')\n",
    "    plt.imshow(image.resize((1024, 1024)), alpha=0.1)\n",
    "    plt.title(f'Recall: {recall:.2f}')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(missing_contour, cmap='Reds')\n",
    "    plt.imshow(pred_contour, cmap='Blues', alpha=0.3)\n",
    "    plt.title('Predicted')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # plt.figure(figsize=(20, 20))\n",
    "\n",
    "    # token_per_side = 8\n",
    "\n",
    "    # for i in range(token_per_side * token_per_side):\n",
    "    #     plt.subplot(token_per_side, token_per_side, i + 1)\n",
    "    #     plt.imshow(batch_masks[0][i], cmap='Blues')\n",
    "    #     plt.imshow(image, alpha=0.1)\n",
    "    #     plt.axis('off')\n",
    "    #     # plt.title(batch_masks[0][i].sum())\n",
    "\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics and Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps = 3\n",
    "# effective_masks = []\n",
    "# mask_sizes = []\n",
    "# for _ in tqdm.tqdm(range(steps)):\n",
    "#     image = dataset[random.randint(0, len(dataset) - 1)]['image']\n",
    "#     image = image.resize((image_resolution, image_resolution))\n",
    "#     masks = visual_tokenizer(image)[0].cpu().numpy()\n",
    "\n",
    "#     effective_masks.append((np.sum(masks, axis=(1, 2))>0).sum())\n",
    "#     mask_sizes.append(np.sum(masks, axis=(1, 2)))\n",
    "\n",
    "# mask_sizes = np.array(mask_sizes) / (image_resolution * image_resolution)* 100\n",
    "# avg_mask_sizes = np.mean(mask_sizes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "\n",
    "# for sample_mask_sizes in mask_sizes:\n",
    "#     plt.plot(sample_mask_sizes, alpha=0.1)\n",
    "\n",
    "# plt.plot(avg_mask_sizes, color='black', linewidth=2)\n",
    "\n",
    "# # plot horizontal line of 10%, 1%, 0.1% and mark text\n",
    "# for y in [1, 50, 10, 1, 0.1]:\n",
    "#     plt.axhline(y=y, color='r', linestyle='--')\n",
    "#     plt.text(0, y*1.1, f'{y}%', color='r')\n",
    "\n",
    "# # # plot vertical line of 32 tokens, 64 tokens, 128 tokens and mark text\n",
    "# for x in [4, 9, 16, 25, 36, 64, 81, 100]:\n",
    "#     if x >= max_tokens:\n",
    "#         continue\n",
    "#     plt.axvline(x=x-1, color='b', linestyle='--')\n",
    "#     plt.scatter(x-1, avg_mask_sizes[x-1], color='b')\n",
    "#     plt.text(x+1, avg_mask_sizes[x-1], f'{x} tokens ({avg_mask_sizes[x-1]:.3f}%)', color='b')\n",
    "\n",
    "# #log y axis\n",
    "# plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.hist(effective_masks, bins=50)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subobjects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
