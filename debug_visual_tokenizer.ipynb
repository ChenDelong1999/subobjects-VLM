{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from visual_tokenizer import get_visual_tokenizer\n",
    "from utils.visualization import visualize_masks\n",
    "from data import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = get_dataset('imagenet', '/share/datasets/imagenet', split='train')\n",
    "# dataset = get_dataset('coco', '/share/datasets/coco2017', split='train')\n",
    "# dataset = get_dataset('clevr_caption', '/home/dchenbs/workspace/datasets/CLEVR_v1.0', split='train')\n",
    "# dataset = get_dataset('image_paragraph_captioning', '/home/dchenbs/workspace/datasets/VisualGenome', split='train')\n",
    "\n",
    "# datset = get_dataset('sharegpt4v', '/home/dchenbs/workspace/datasets/sharegpt4v/ShareGPT4V/sharegpt4v_mix665k_cap23k_coco-ap9k_lcs3k_sam9k_div2k.json', split='train')\n",
    "# dataset = get_dataset('sharegpt4v', '/home/dchenbs/workspace/datasets/sharegpt4v/ShareGPT4V/share-captioner_coco_lcs_sam_1246k_1107.json', split='train')\n",
    "dataset = get_dataset('sharegpt4v', '/home/dchenbs/workspace/datasets/sharegpt4v/ShareGPT4V/sharegpt4v_instruct_gpt4-vision_cap100k.json', split='train')\n",
    "\n",
    "# dataset = ShareGPT4V('/home/dchenbs/workspace/datasets/sharegpt4v/ShareGPT4V/sharegpt4v_mix665k_cap23k_coco-ap9k_lcs3k_sam9k_div2k.json', split=split)\n",
    "# dataset = ShareGPT4V('/home/dchenbs/workspace/datasets/sharegpt4v/ShareGPT4V/share-captioner_coco_lcs_sam_1246k_1107.json', split=split)\n",
    "# dataset = ShareGPT4V('/home/dchenbs/workspace/datasets/sharegpt4v/ShareGPT4V/sharegpt4v_instruct_gpt4-vision_cap100k.json', split=split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resolution = 1024\n",
    "max_tokens = 256\n",
    "\n",
    "# config = json.load(open('configs/visual_tokenizer/patch_8_per_side_random.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/patch_8_per_side_raster.json'))\n",
    "# config = json.load(open('configs/visual_tokenizer/directsam_0424.json'))\n",
    "config = json.load(open('configs/visual_tokenizer/directsam_tiny.json'))\n",
    "\n",
    "visual_tokenizer = get_visual_tokenizer(**config, image_resolution=image_resolution, max_tokens=max_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    sample = dataset[random.randint(0, len(dataset) - 1)]\n",
    "    image = sample['image'].resize((image_resolution, image_resolution))\n",
    "    batch_masks = visual_tokenizer(image)\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(visualize_masks(image, batch_masks[0]))\n",
    "    plt.title((np.sum(batch_masks[0], axis=(1, 2)) > 0).sum())\n",
    "\n",
    "\n",
    "    labels = np.zeros_like(batch_masks[0][0]).astype(np.int32)\n",
    "    for i, mask in enumerate(batch_masks[0]):\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        labels += (i + 1) * mask\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(labels, cmap='plasma')\n",
    "    plt.title('order')\n",
    "\n",
    "    print(sample['text'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics and Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 100\n",
    "effective_masks = []\n",
    "for _ in tqdm.tqdm(range(steps)):\n",
    "    image = dataset[random.randint(0, len(dataset) - 1)]['image']\n",
    "    image = image.resize((image_resolution, image_resolution))\n",
    "    masks = visual_tokenizer(image)[0]\n",
    "\n",
    "    effective_masks.append((np.sum(masks, axis=(1, 2))>0).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(effective_masks, bins=50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "univlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
