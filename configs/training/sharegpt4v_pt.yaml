# Training Hyperparameters
  training_args:
    logging_steps: 1
    save_steps: 500
    save_total_limit: 100

    learning_rate: !!float 2e-5
    lr_scheduler_type: 'constant_with_warmup'
    warmup_steps: 470
    weight_decay: 0.05

  # speed-up training
    bf16: True
    torch_compile: True
    ddp_find_unused_parameters: False
    dataloader_prefetch_factor: 4

  # evalutaion
    do_eval: False