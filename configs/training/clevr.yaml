# Training Hyperparameters
  training_args:
    logging_steps: 1
    save_steps: 500
    save_total_limit: 1

    learning_rate: !!float 1e-4
    lr_scheduler_type: 'cosine'
    warmup_steps: 500
    weight_decay: 0.05

  # speed-up training
    bf16: True
    torch_compile: True
    ddp_find_unused_parameters: False
    dataloader_prefetch_factor: 4

  # evalutaion
    do_eval: False