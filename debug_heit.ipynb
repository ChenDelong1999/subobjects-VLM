{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "from datasets import load_dataset\n",
    "from utils.visualization import visualize_masks\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "from HEIT.metrics import create_circular_kernel, masks_to_contour, contour_recall\n",
    "\n",
    "\n",
    "def get_samples(output_dir, split, resolution, model):\n",
    "    samples_dict = {}\n",
    "    results_dir = f'{output_dir}/{split}/{resolution}/{model}'\n",
    "    for file in os.listdir(results_dir):\n",
    "        samples_dict[int(file.split('.')[0])] = os.path.join(results_dir, file)\n",
    "\n",
    "    samples = []\n",
    "    for index in range(len(samples_dict)):\n",
    "        samples.append(samples_dict[index])\n",
    "\n",
    "    return samples\n",
    "\n",
    "def decode_masks(sample_json):\n",
    "    masks_rle = json.load(open(sample_json))\n",
    "    masks = []\n",
    "    for mask_rle in masks_rle:\n",
    "        mask = mask_util.decode(mask_rle)\n",
    "        masks.append(mask)\n",
    "    masks = np.array(masks)\n",
    "    return masks\n",
    "    \n",
    "output_dir = 'HEIT/outputs/tokenized_HEIT'\n",
    "resolution = 1024\n",
    "\n",
    "\n",
    "splits = [\n",
    "    'SA1B', 'COCONut_relabeld_COCO_val', 'EntitySeg', 'PascalPanopticParts', 'plantorgans', 'MapillaryMetropolis', \n",
    "    'cityscapes', 'NYUDepthv2', 'tcd', 'FoodSeg103', 'ADE20k', 'WireFrame', 'ISAID', 'PhenoBench', 'EgoHOS', 'LIP', \n",
    "    'SOBA', 'CIHP', 'LoveDA', 'SPIN', 'SUIM', 'MyFood', 'DIS5K_DIS_VD', 'DUTS_TE', 'Fashionpedia', 'PartImageNetPP', \n",
    "    'SeginW', 'LVIS', 'PACO', 'DRAM'\n",
    "    ]\n",
    "\n",
    "split = 'EntitySeg'\n",
    "dataset = load_dataset(\"chendelong/HEIT\", split=split)\n",
    "print(dataset)\n",
    "print(dataset[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in splits:\n",
    "    print('='*64)\n",
    "    print(split)\n",
    "    print('-'*64)\n",
    "    dataset = load_dataset(\"chendelong/HEIT\", split=split)\n",
    "\n",
    "    models = []\n",
    "    for model in os.listdir(f'{output_dir}/{split}/{resolution}'):\n",
    "        # # model = 'superpixel_slic'\n",
    "        # model = 'directsam_tiny_dsa_100ep@0.05'\n",
    "        # # model = 'mobilesamv2'\n",
    "\n",
    "        samples = get_samples(output_dir, split, resolution, model)\n",
    "        if len(samples) == len(dataset):\n",
    "            models.append(model)\n",
    "        else:\n",
    "            print(f'{model} only has {len(samples)}/{len(dataset)} samples')\n",
    "\n",
    "    print('---')\n",
    "    models.sort()\n",
    "    for model in models:\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def masks_to_contour_torch(masks, tolerance, device='cuda'):\n",
    "    \"\"\"\n",
    "    Converts a set of masks to a contour map using PyTorch.\n",
    "\n",
    "    Args:\n",
    "        masks (torch.Tensor): A tensor of shape (N, H, W), where N is the number of masks.\n",
    "        tolerance (int): The size of the neighborhood to consider for detecting edges.\n",
    "\n",
    "    Returns:\n",
    "        torch.BoolTensor: A boolean tensor of shape (H_resized, W_resized) indicating the contour.\n",
    "    \"\"\"\n",
    "    # Ensure masks are in torch.Tensor format and move to device\n",
    "    if not isinstance(masks, torch.Tensor):\n",
    "        masks = torch.tensor(masks, device=device)\n",
    "    else:\n",
    "        masks = masks.to(device)\n",
    "\n",
    "    # Create label map\n",
    "    label_map = torch.zeros_like(masks[0], dtype=torch.int64)\n",
    "    for i, mask in enumerate(masks):\n",
    "        if torch.sum(mask) == 0:\n",
    "            continue\n",
    "        label_map += (i + 1) * mask\n",
    "\n",
    "    # Resize label_map to (1024, 1024)\n",
    "    label_map = label_map.unsqueeze(0).unsqueeze(0).float()  # Shape: (1, 1, H, W)\n",
    "    label_map = F.interpolate(label_map, size=(1024, 1024), mode='nearest')\n",
    "    label_map = label_map.squeeze(0).squeeze(0).long()  # Shape: (1024, 1024)\n",
    "\n",
    "    # Perform dilation\n",
    "    label_map = label_map.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, H, W)\n",
    "    dilated = F.max_pool2d(label_map.float(), kernel_size=2 * tolerance + 1, stride=1, padding=tolerance)\n",
    "    # Perform erosion\n",
    "    eroded = -F.max_pool2d(-label_map.float(), kernel_size=2 * tolerance + 1, stride=1, padding=tolerance)\n",
    "\n",
    "    # Compute boundaries\n",
    "    boundaries = (dilated != eroded).squeeze(0).squeeze(0)\n",
    "    boundaries &= label_map.squeeze(0).squeeze(0) != 0\n",
    "    boundaries = boundaries.bool()\n",
    "\n",
    "    return boundaries\n",
    "\n",
    "def calculate_metrics(image, gt_contour, masks, tolerance, do_visualization=False, device='cuda'):\n",
    "    # Ensure masks are in torch.Tensor format and move to device\n",
    "    if not isinstance(masks, torch.Tensor):\n",
    "        masks = torch.tensor(masks)\n",
    "    masks = masks.to(device)\n",
    "\n",
    "    # Remove empty masks\n",
    "    mask_sums = masks.sum(dim=(1, 2))\n",
    "    masks = masks[mask_sums > 0]\n",
    "\n",
    "    # Process ground truth contour\n",
    "    gt_contour[:tolerance] = gt_contour[-tolerance:] = gt_contour[:, :tolerance] = gt_contour[:, -tolerance:] = 0\n",
    "    gt_contour = torch.tensor(gt_contour, device=device).bool()\n",
    "\n",
    "    # Get predicted contour\n",
    "    pred_contour = masks_to_contour_torch(masks, tolerance, device=device)\n",
    "\n",
    "    # Compute True Positives (TP), False Positives (FP), and False Negatives (FN)\n",
    "    TP = (gt_contour & pred_contour).sum().item()\n",
    "    FP = ((~gt_contour) & pred_contour).sum().item()\n",
    "    FN = (gt_contour & (~pred_contour)).sum().item()\n",
    "\n",
    "    # Compute precision, recall, and F1 score\n",
    "    if gt_contour.sum().item() == 0:\n",
    "        precision = 1.0\n",
    "        recall = 1.0\n",
    "        f1 = 1.0\n",
    "    else:\n",
    "        precision = TP / (TP + FP + 1e-8)\n",
    "        recall = TP / (TP + FN + 1e-8)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\n",
    "    # Sort masks based on the number of pixels, from large to small\n",
    "    mask_sizes = masks.sum(dim=(1, 2))\n",
    "    sorted_indices = torch.argsort(mask_sizes, descending=True)\n",
    "    masks = masks[sorted_indices]\n",
    "    mask_sizes = mask_sizes[sorted_indices].tolist()\n",
    "\n",
    "    metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'mask_sizes': mask_sizes\n",
    "    }\n",
    "\n",
    "    if do_visualization:\n",
    "        plt.figure(figsize=(40, 10))\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(image)\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(visualize_masks(image, masks.cpu().numpy()))\n",
    "        plt.title(f\"{(masks.sum(dim=(1, 2)) > 0).sum().item()} tokens\")\n",
    "\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(gt_contour.cpu().numpy(), cmap='Greens')\n",
    "        plt.title('Ground Truth')\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(pred_contour.cpu().numpy(), cmap='Blues', alpha=0.3)\n",
    "        plt.title(f'Predicted: P={precision:.2f}, R={recall:.2f}, F1={f1:.2f}')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = 'directsam_tiny_dsa_100ep@0.1'\n",
    "samples = get_samples(output_dir, split, resolution, model)\n",
    "\n",
    "tolerance = 5\n",
    "max_tokens = 576\n",
    "\n",
    "all_metrics = []\n",
    "for i in tqdm.tqdm(range(20)):\n",
    "    sample = dataset[i]\n",
    "    image = np.array(sample['image'])\n",
    "    gt_contour = np.array(sample['contour'])\n",
    "\n",
    "    masks = decode_masks(samples[i]).astype(np.int32)\n",
    "\n",
    "\n",
    "    if len(masks) > max_tokens:\n",
    "        print(f\"Sample {i} has {len(masks)} tokens\")\n",
    "        masks = masks[:max_tokens]\n",
    "\n",
    "    metrics = calculate_metrics(image, gt_contour, masks, tolerance=tolerance, do_visualization=True)\n",
    "    all_metrics.append(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_mask_sizes = np.zeros((len(all_metrics), max_tokens), dtype=np.int32)\n",
    "for i, metrics in enumerate(all_metrics):\n",
    "    all_mask_sizes[i, :len(metrics['mask_sizes'])] = metrics['mask_sizes'][:max_tokens]\n",
    "\n",
    "accumulated_mask_sizes = np.cumsum(all_mask_sizes, axis=1) / (resolution * resolution)\n",
    "accumulated_mask_sizes = np.mean(accumulated_mask_sizes, axis=0)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(accumulated_mask_sizes)\n",
    "\n",
    "# plot the point that it reaches 99% and 100% of the total area\n",
    "for percentage in [0.90, 0.95, 0.98, 0.99]:\n",
    "    if accumulated_mask_sizes[-1] >= percentage:\n",
    "        x = np.argmax(accumulated_mask_sizes >= percentage)\n",
    "        plt.plot(x, percentage, 'ro')\n",
    "        plt.text(x, percentage, f'{percentage:.0%}:{x} tokens', va='bottom', ha='right')\n",
    "\n",
    "plt.xlim(0, max_tokens)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subobjects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
