{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import tqdm\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.visualization import visualize_sample\n",
    "from model.utils import create_vlm\n",
    "from model.utils import VisualTextualTokenization\n",
    "from data import get_dataset\n",
    "from visual_tokenizer import get_visual_tokenizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from data import (\n",
    "    ShareGPT4V,\n",
    "    ImageNet,\n",
    "    Cambrian\n",
    ")\n",
    "\n",
    "dataset = ShareGPT4V(\n",
    "    root='/private/home/delong/workspace/data/ShareGPT4V',\n",
    "    split='sharegpt4v_instruct_gpt4-vision_cap100k.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"/private/home/delong/workspace/subobjects-VLM/runs/sharegpt4v/1106-1359-patch_6_per_side_raster(36)-clip_vit_l_14_336-SmolLM2-1_7B-Instruct/checkpoint-2000\"\n",
    "model, textual_tokenizer = create_vlm(checkpoint)\n",
    "\n",
    "model = model.cuda().half().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resolution = 384\n",
    "max_tokens = 36\n",
    "\n",
    "config = json.load(open('configs/visual_tokenizer/directsam/directsam_tiny_dsa_100ep@0.1.json'))\n",
    "\n",
    "\n",
    "visual_tokenizer = get_visual_tokenizer(**config, image_resolution=image_resolution, max_tokens=max_tokens)\n",
    "\n",
    "vl_tokenizer = VisualTextualTokenization(textual_tokenizer, visual_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "loss = 0\n",
    "for _ in tqdm.tqdm(range(n_samples)):\n",
    "    sample = dataset[random.randint(0, len(dataset))]\n",
    "    inputs = vl_tokenizer([sample], eval=True)\n",
    "\n",
    "    # print(inputs.keys(), inputs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        loss += outputs['loss'].item()\n",
    "\n",
    "print(f\"Loss: {loss / n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[random.randint(0, len(dataset))]\n",
    "\n",
    "label = sample['text'].split('<|assistant|>')[1].strip().replace(textual_tokenizer.eos_token, '')\n",
    "sample['text'] = sample['text'].split('<|assistant|>')[0] + '<|assistant|>'\n",
    "\n",
    "inputs = vl_tokenizer([sample], eval=True)\n",
    "\n",
    "\n",
    "inputs_embeds, labels = model.prepare_inputs_embeds(\n",
    "    inputs['text'], inputs['image'], inputs['masks']\n",
    ")\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs_embeds=inputs_embeds,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=dataset.max_text_tokens,\n",
    "    eos_token_id = textual_tokenizer.eos_token_id,\n",
    "    pad_token_id = textual_tokenizer.pad_token_id,\n",
    ")\n",
    "prediction = textual_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "visualize_sample(sample, inputs)\n",
    "print(label)\n",
    "print('-' * 80)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subobjects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
